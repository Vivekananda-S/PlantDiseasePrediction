{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96c2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53aa78bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14440 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69faa079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.691745   0.6172352  0.6250783 ]\n",
      "  [0.6897121  0.6152023  0.62304544]\n",
      "  [0.6876792  0.6131694  0.6210125 ]\n",
      "  ...\n",
      "  [0.7378971  0.6673088  0.6673088 ]\n",
      "  [0.73976    0.6691717  0.6691717 ]\n",
      "  [0.7537404  0.68315214 0.68315214]]\n",
      "\n",
      " [[0.70498407 0.6304742  0.63831735]\n",
      "  [0.7034594  0.6289495  0.63679266]\n",
      "  [0.70193475 0.62742496 0.6352681 ]\n",
      "  ...\n",
      "  [0.73688066 0.6662924  0.6662924 ]\n",
      "  [0.74179286 0.6712046  0.6712046 ]\n",
      "  [0.75526506 0.6846768  0.6846768 ]]\n",
      "\n",
      " [[0.7075221  0.6330123  0.64085543]\n",
      "  [0.70803034 0.63352054 0.6413637 ]\n",
      "  [0.70853853 0.63402873 0.64187187]\n",
      "  ...\n",
      "  [0.73586416 0.66527593 0.66527593]\n",
      "  [0.7438257  0.67323744 0.67323744]\n",
      "  [0.7567897  0.68620145 0.68620145]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.5594528  0.43788415 0.43004102]\n",
      "  [0.5568628  0.43529415 0.427451  ]\n",
      "  [0.5581282  0.43655956 0.42871642]\n",
      "  ...\n",
      "  [0.5676127  0.44996566 0.44212252]\n",
      "  [0.56405514 0.4464081  0.43856496]\n",
      "  [0.5604976  0.44285056 0.43500742]]\n",
      "\n",
      " [[0.5589446  0.43737593 0.4295328 ]\n",
      "  [0.5568628  0.43529415 0.427451  ]\n",
      "  [0.55863637 0.43706778 0.42922464]\n",
      "  ...\n",
      "  [0.5528629  0.4352158  0.42737266]\n",
      "  [0.5574369  0.4397898  0.43194667]\n",
      "  [0.5620108  0.4443638  0.43652064]]\n",
      "\n",
      " [[0.55843633 0.4368677  0.42902458]\n",
      "  [0.5568628  0.43529415 0.427451  ]\n",
      "  [0.5591447  0.437576   0.42973286]\n",
      "  ...\n",
      "  [0.52822644 0.41057938 0.40273625]\n",
      "  [0.53076756 0.41312048 0.40527734]\n",
      "  [0.5333086  0.41566157 0.40781844]]]\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in train_generator:\n",
    "    print(image_batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "625b1b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2058 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'dataset/val',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf985b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4140 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_generator = validation_datagen.flow_from_directory(\n",
    "    'dataset/test',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b162397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape= (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 15\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=input_shape),\n",
    "    layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape = input_shape),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7363002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                975       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184,527\n",
      "Trainable params: 184,527\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c1fb5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now compiling the model\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e37e5b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.3125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#14440/32\n",
    "\n",
    "#2058/32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92cc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "118/451 [======>.......................] - ETA: 10:06 - loss: 2.2975 - accuracy: 0.2375"
     ]
    }
   ],
   "source": [
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=451,\n",
    "#     batch_size=32,\n",
    "#     validation_data = validation_generator,\n",
    "#     validation_steps = 64,\n",
    "#     verbose=1,\n",
    "#     epochs=30\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec1d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
